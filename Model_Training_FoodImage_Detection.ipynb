{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cce2170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "103d6397-f7bb-4b42-9633-f2c942166b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85abbe86-366d-47a0-8560-a6aee703ef97",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38a9be68-d13a-4216-a756-a20255b426f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09e35c6f-6cbb-48b2-b992-c8c5ca5d9842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78400 images belonging to 98 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'food101/images',               \n",
    "    target_size=(224, 224),   \n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  \n",
    "    subset='training',\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab70b99-591b-4b7f-b4d5-4c1931e0a1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19600 images belonging to 98 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = train_datagen.flow_from_directory(\n",
    "    'food101/images',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c010876-8533-4627-a686-340b5f6fb307",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "319bed85-af57-4b77-b436-ac1fc248be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5c13a53-b8b2-41ca-b1f1-34237c101f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c6b52cd-da2b-4f2a-ada0-f80106cbddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99888389-053e-4eda-a013-9f0733f1339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04c448e2-cf41-45d0-94a4-e78a1ab610d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shristi Kumari\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2450/2450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3108s\u001b[0m 1s/step - accuracy: 0.4464 - loss: 2.2157 - val_accuracy: 0.5158 - val_loss: 1.8895\n",
      "Epoch 2/5\n",
      "\u001b[1m2450/2450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3171s\u001b[0m 1s/step - accuracy: 0.5559 - loss: 1.7138 - val_accuracy: 0.5289 - val_loss: 1.8497\n",
      "Epoch 3/5\n",
      "\u001b[1m2450/2450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3395s\u001b[0m 1s/step - accuracy: 0.5865 - loss: 1.5699 - val_accuracy: 0.5346 - val_loss: 1.8648\n",
      "Epoch 4/5\n",
      "\u001b[1m2450/2450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2899s\u001b[0m 1s/step - accuracy: 0.6093 - loss: 1.4646 - val_accuracy: 0.5432 - val_loss: 1.8396\n",
      "Epoch 5/5\n",
      "\u001b[1m2450/2450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3063s\u001b[0m 1s/step - accuracy: 0.6288 - loss: 1.3833 - val_accuracy: 0.5405 - val_loss: 1.8644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17a397c7e00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3161398-6140-4243-b959-dfde7253bfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m2450/2450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3357s\u001b[0m 1s/step - accuracy: 0.6453 - loss: 1.3153 - val_accuracy: 0.5371 - val_loss: 1.9256\n",
      "Epoch 2/3\n",
      "\u001b[1m2450/2450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4677s\u001b[0m 2s/step - accuracy: 0.6573 - loss: 1.2560 - val_accuracy: 0.5343 - val_loss: 1.9510\n",
      "Epoch 3/3\n",
      "\u001b[1m2450/2450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2881s\u001b[0m 1s/step - accuracy: 0.6705 - loss: 1.2032 - val_accuracy: 0.5338 - val_loss: 2.0066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17a3bb63250>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "facac057-102e-431d-a556-276c512c5a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m2450/2450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2984s\u001b[0m 1s/step - accuracy: 0.6797 - loss: 1.1561 - val_accuracy: 0.5288 - val_loss: 2.0712\n",
      "Epoch 2/2\n",
      "\u001b[1m2450/2450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2892s\u001b[0m 1s/step - accuracy: 0.6909 - loss: 1.1132 - val_accuracy: 0.5307 - val_loss: 2.0935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17a3bb61810>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6443161-16a3-4fc9-ab9f-e309582847fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shristi Kumari\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m  56/2450\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50:04\u001b[0m 1s/step - accuracy: 0.0344 - loss: 4.6002        "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator, \n",
    "    epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428b1f69-319d-462e-887d-cb1b576fe25f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fdfa70c-ff1b-42e6-9a7f-93919d543912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('food_prediction_10epoches.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7683514e-375c-4ceb-9aa5-1b6e962df85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98fcbfa3-1383-405f-874a-bf6eda1c1527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('food_prediction_10epoches.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "353b85e5-a8e0-494f-ab67-e7d71affcc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'img3.png' \n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = x / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dbf23296-a8fe-477c-b9f3-fe3259e156fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a286790a-c13b-4bae-91a6-22d792ca7e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(train_generator.class_indices.keys())\n",
    "predicted_class = labels[np.argmax(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5102f0db-6e9d-4aa7-92be-abca95651505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Food Name: cup_cakes\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted Food Name:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9397cc6-b1f8-47b1-985b-3894583fc03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b944e32-afdc-4a7e-a397-42e807b78700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed349e4-6887-46c6-bafb-90401a73c4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
